{"id":852,"text":"#G17# As an app developer, I want to include the code of a dataset type in my app artifact and create a dataset of that type when deploying the app.","entities":[{"id":6956,"label":"PID","start_offset":0,"end_offset":5},{"id":6957,"label":"Persona","start_offset":12,"end_offset":25},{"id":6958,"label":"Action","start_offset":37,"end_offset":44},{"id":6959,"label":"Entity","start_offset":49,"end_offset":53},{"id":6960,"label":"Entity","start_offset":59,"end_offset":71},{"id":6961,"label":"Entity","start_offset":78,"end_offset":90},{"id":6962,"label":"Action","start_offset":95,"end_offset":101},{"id":6965,"label":"Action","start_offset":130,"end_offset":139},{"id":6966,"label":"Entity","start_offset":144,"end_offset":147},{"id":7322,"label":"Entity","start_offset":104,"end_offset":124}],"relations":[{"id":4002,"from_id":6957,"to_id":6958,"type":"triggers"},{"id":4003,"from_id":6958,"to_id":6959,"type":"targets"},{"id":4004,"from_id":6960,"to_id":6959,"type":"contains"},{"id":4005,"from_id":6961,"to_id":6959,"type":"contains"},{"id":4007,"from_id":6965,"to_id":6966,"type":"targets"},{"id":4148,"from_id":6957,"to_id":6962,"type":"triggers"},{"id":4249,"from_id":6962,"to_id":7322,"type":"targets"}]}
{"id":853,"text":"#G17# As an app developer, I want to deploy a new version of a dataset type as part of deploying a new version of the app that includes it and I expect that all dataset instances of that type that were created as part of the app deployment start using the new code.","entities":[{"id":7063,"label":"PID","start_offset":0,"end_offset":5},{"id":7064,"label":"Persona","start_offset":12,"end_offset":25},{"id":7065,"label":"Action","start_offset":37,"end_offset":43},{"id":7066,"label":"Entity","start_offset":46,"end_offset":57},{"id":7067,"label":"Entity","start_offset":63,"end_offset":75},{"id":7068,"label":"Action","start_offset":87,"end_offset":96},{"id":7069,"label":"Entity","start_offset":99,"end_offset":110},{"id":7070,"label":"Entity","start_offset":118,"end_offset":121},{"id":7071,"label":"Action","start_offset":127,"end_offset":135},{"id":7075,"label":"Entity","start_offset":225,"end_offset":239},{"id":7076,"label":"Action","start_offset":240,"end_offset":251},{"id":7077,"label":"Entity","start_offset":256,"end_offset":264},{"id":7212,"label":"Entity","start_offset":157,"end_offset":191}],"relations":[{"id":4061,"from_id":7064,"to_id":7065,"type":"triggers"},{"id":4062,"from_id":7065,"to_id":7066,"type":"targets"},{"id":4063,"from_id":7067,"to_id":7066,"type":"contains"},{"id":4064,"from_id":7068,"to_id":7069,"type":"targets"},{"id":4066,"from_id":7070,"to_id":7069,"type":"contains"},{"id":4069,"from_id":7076,"to_id":7077,"type":"targets"},{"id":4070,"from_id":7071,"to_id":7067,"type":"targets"}]}
{"id":854,"text":"#G17# As an app developer, I want to deploy a new version of a dataset type as part of an app artifact, without affecting other datasets of this type.","entities":[{"id":7178,"label":"PID","start_offset":0,"end_offset":5},{"id":7179,"label":"Persona","start_offset":12,"end_offset":25},{"id":7180,"label":"Action","start_offset":37,"end_offset":43},{"id":7181,"label":"Entity","start_offset":46,"end_offset":57},{"id":7182,"label":"Entity","start_offset":63,"end_offset":75},{"id":7183,"label":"Entity","start_offset":90,"end_offset":102},{"id":7205,"label":"Entity","start_offset":122,"end_offset":149}],"relations":[{"id":4127,"from_id":7179,"to_id":7180,"type":"triggers"},{"id":4128,"from_id":7180,"to_id":7181,"type":"targets"},{"id":4129,"from_id":7182,"to_id":7181,"type":"contains"},{"id":4134,"from_id":7183,"to_id":7182,"type":"contains"}]}
{"id":855,"text":"#G17# As an app developer, I want to explore a dataset instance of a type that was deployed as part of an app.","entities":[{"id":7301,"label":"PID","start_offset":0,"end_offset":5},{"id":7302,"label":"Persona","start_offset":12,"end_offset":25},{"id":7303,"label":"Action","start_offset":37,"end_offset":44},{"id":7305,"label":"Entity","start_offset":47,"end_offset":73},{"id":7306,"label":"Entity","start_offset":106,"end_offset":109}],"relations":[{"id":4236,"from_id":7302,"to_id":7303,"type":"triggers"},{"id":4237,"from_id":7303,"to_id":7305,"type":"targets"},{"id":4238,"from_id":7306,"to_id":7305,"type":"contains"}]}
{"id":856,"text":"#G17# As an app developer, I want to ensure that when I deploy an artifact without creating an app this will not create any dataset types or instances.","entities":[{"id":7380,"label":"PID","start_offset":0,"end_offset":5},{"id":7381,"label":"Persona","start_offset":12,"end_offset":25},{"id":7382,"label":"Action","start_offset":37,"end_offset":43},{"id":7383,"label":"Action","start_offset":56,"end_offset":62},{"id":7384,"label":"Entity","start_offset":66,"end_offset":74},{"id":7385,"label":"Entity","start_offset":95,"end_offset":98},{"id":7386,"label":"Action","start_offset":104,"end_offset":119},{"id":7387,"label":"Entity","start_offset":124,"end_offset":137},{"id":7388,"label":"Entity","start_offset":141,"end_offset":150}],"relations":[{"id":4275,"from_id":7381,"to_id":7382,"type":"triggers"},{"id":4276,"from_id":7383,"to_id":7384,"type":"targets"},{"id":4277,"from_id":7386,"to_id":7387,"type":"targets"},{"id":4278,"from_id":7386,"to_id":7388,"type":"targets"}]}
{"id":857,"text":"#G17# As an app developer, I want to share a dataset type across multiple applications that include the dataset type's code in their artifacts.","entities":[{"id":7465,"label":"PID","start_offset":0,"end_offset":5},{"id":7466,"label":"Persona","start_offset":12,"end_offset":25},{"id":7467,"label":"Action","start_offset":37,"end_offset":42},{"id":7468,"label":"Entity","start_offset":45,"end_offset":57},{"id":7469,"label":"Entity","start_offset":65,"end_offset":86},{"id":7470,"label":"Entity","start_offset":104,"end_offset":123},{"id":7471,"label":"Entity","start_offset":133,"end_offset":142}],"relations":[{"id":4316,"from_id":7466,"to_id":7467,"type":"triggers"},{"id":4317,"from_id":7467,"to_id":7468,"type":"targets"},{"id":4318,"from_id":7471,"to_id":7470,"type":"contains"},{"id":4319,"from_id":7469,"to_id":7471,"type":"contains"}]}
{"id":858,"text":"#G17# As an app developer, I want to ensure that when I deploy a new version of an app that includes a shared dataset type that all dataset instances created by this app start using the new code but all dataset instances created by other apps remain unchanged.","entities":[{"id":6967,"label":"PID","start_offset":0,"end_offset":5},{"id":6968,"label":"Persona","start_offset":12,"end_offset":25},{"id":6969,"label":"Action","start_offset":37,"end_offset":43},{"id":6970,"label":"Action","start_offset":56,"end_offset":62},{"id":6971,"label":"Entity","start_offset":65,"end_offset":76},{"id":6972,"label":"Entity","start_offset":83,"end_offset":86},{"id":6973,"label":"Entity","start_offset":103,"end_offset":122},{"id":6974,"label":"Entity","start_offset":132,"end_offset":149},{"id":6975,"label":"Entity","start_offset":166,"end_offset":169},{"id":6977,"label":"Action","start_offset":170,"end_offset":181},{"id":6978,"label":"Entity","start_offset":186,"end_offset":194},{"id":6979,"label":"Entity","start_offset":199,"end_offset":220},{"id":6981,"label":"Entity","start_offset":232,"end_offset":242},{"id":6982,"label":"Action","start_offset":243,"end_offset":259}],"relations":[{"id":4009,"from_id":6968,"to_id":6969,"type":"triggers"},{"id":4010,"from_id":6970,"to_id":6971,"type":"triggers"},{"id":4011,"from_id":6972,"to_id":6971,"type":"contains"},{"id":4014,"from_id":6977,"to_id":6978,"type":"targets"},{"id":4016,"from_id":6982,"to_id":6979,"type":"targets"},{"id":4158,"from_id":6971,"to_id":6973,"type":"contains"}]}
{"id":859,"text":"#G17# As an app developer, I want to ensure that when I deploy a new version of an app that includes an older version of a dataset type deployed by another app and I expect that the dataset instances created by this app use the dataset type code included in this app.","entities":[{"id":7078,"label":"PID","start_offset":0,"end_offset":5},{"id":7079,"label":"Persona","start_offset":12,"end_offset":25},{"id":7080,"label":"Action","start_offset":37,"end_offset":43},{"id":7081,"label":"Action","start_offset":56,"end_offset":62},{"id":7082,"label":"Entity","start_offset":65,"end_offset":76},{"id":7083,"label":"Entity","start_offset":83,"end_offset":86},{"id":7084,"label":"Entity","start_offset":104,"end_offset":117},{"id":7085,"label":"Entity","start_offset":123,"end_offset":135},{"id":7087,"label":"Entity","start_offset":148,"end_offset":159},{"id":7089,"label":"Entity","start_offset":182,"end_offset":199},{"id":7090,"label":"Entity","start_offset":216,"end_offset":219},{"id":7091,"label":"Action","start_offset":220,"end_offset":223},{"id":7092,"label":"Entity","start_offset":228,"end_offset":245},{"id":7093,"label":"Entity","start_offset":263,"end_offset":266}],"relations":[{"id":4073,"from_id":7079,"to_id":7080,"type":"triggers"},{"id":4074,"from_id":7081,"to_id":7082,"type":"targets"},{"id":4075,"from_id":7083,"to_id":7082,"type":"contains"},{"id":4078,"from_id":7085,"to_id":7084,"type":"contains"},{"id":4080,"from_id":7091,"to_id":7092,"type":"targets"},{"id":4081,"from_id":7093,"to_id":7092,"type":"contains"},{"id":4157,"from_id":7082,"to_id":7085,"type":"contains"}]}
{"id":860,"text":"#G17# As an app developer, I want to ensure that when I deploy a new version of an app that includes a different version of a dataset type deployed by another app and this app shares a dataset instance of this type with the other app the deployment will fail with a version conflict error.","entities":[{"id":7187,"label":"PID","start_offset":0,"end_offset":5},{"id":7188,"label":"Persona","start_offset":12,"end_offset":25},{"id":7189,"label":"Action","start_offset":37,"end_offset":43},{"id":7190,"label":"Action","start_offset":56,"end_offset":62},{"id":7191,"label":"Entity","start_offset":65,"end_offset":76},{"id":7192,"label":"Entity","start_offset":83,"end_offset":86},{"id":7193,"label":"Entity","start_offset":103,"end_offset":120},{"id":7194,"label":"Entity","start_offset":126,"end_offset":138},{"id":7195,"label":"Entity","start_offset":151,"end_offset":162},{"id":7196,"label":"Entity","start_offset":172,"end_offset":175},{"id":7197,"label":"Action","start_offset":176,"end_offset":182},{"id":7200,"label":"Entity","start_offset":224,"end_offset":233},{"id":7201,"label":"Entity","start_offset":238,"end_offset":248},{"id":7202,"label":"Action","start_offset":254,"end_offset":258},{"id":7203,"label":"Entity","start_offset":266,"end_offset":288},{"id":7204,"label":"Entity","start_offset":185,"end_offset":214}],"relations":[{"id":4135,"from_id":7188,"to_id":7189,"type":"triggers"},{"id":4136,"from_id":7190,"to_id":7191,"type":"targets"},{"id":4137,"from_id":7192,"to_id":7191,"type":"contains"},{"id":4139,"from_id":7194,"to_id":7193,"type":"contains"},{"id":4142,"from_id":7201,"to_id":7203,"type":"contains"},{"id":4145,"from_id":7197,"to_id":7204,"type":"targets"},{"id":4159,"from_id":7191,"to_id":7194,"type":"contains"}]}
{"id":861,"text":"#G17# As an app developer, I want to share a dataset type that I had previously deployed as part of an app.","entities":[{"id":7307,"label":"PID","start_offset":0,"end_offset":5},{"id":7308,"label":"Persona","start_offset":12,"end_offset":25},{"id":7309,"label":"Action","start_offset":37,"end_offset":42},{"id":7310,"label":"Entity","start_offset":45,"end_offset":57},{"id":7311,"label":"Entity","start_offset":103,"end_offset":106}],"relations":[{"id":4239,"from_id":7308,"to_id":7309,"type":"triggers"},{"id":4240,"from_id":7309,"to_id":7310,"type":"targets"},{"id":4241,"from_id":7311,"to_id":7310,"type":"contains"}]}
{"id":862,"text":"#G17# As a dataset developer, I want to deploy a dataset type independent from any app and allow apps to create and use dataset instances of that type.","entities":[{"id":7389,"label":"PID","start_offset":0,"end_offset":5},{"id":7390,"label":"Persona","start_offset":11,"end_offset":28},{"id":7391,"label":"Action","start_offset":40,"end_offset":46},{"id":7394,"label":"Action","start_offset":91,"end_offset":96},{"id":7395,"label":"Entity","start_offset":97,"end_offset":101},{"id":7396,"label":"Action","start_offset":105,"end_offset":111},{"id":7397,"label":"Action","start_offset":116,"end_offset":119},{"id":7398,"label":"Entity","start_offset":120,"end_offset":150},{"id":7410,"label":"Entity","start_offset":49,"end_offset":73},{"id":7412,"label":"Entity","start_offset":79,"end_offset":86}],"relations":[{"id":4279,"from_id":7390,"to_id":7391,"type":"triggers"},{"id":4281,"from_id":7394,"to_id":7395,"type":"targets"},{"id":4282,"from_id":7390,"to_id":7394,"type":"triggers"},{"id":4283,"from_id":7396,"to_id":7398,"type":"targets"},{"id":4284,"from_id":7397,"to_id":7398,"type":"targets"},{"id":4291,"from_id":7391,"to_id":7410,"type":"targets"}]}
{"id":863,"text":"#G17# As a dataset developer, I want to have the option of forcing applications to have the dataset code injected at runtime.","entities":[{"id":7472,"label":"PID","start_offset":0,"end_offset":5},{"id":7473,"label":"Persona","start_offset":11,"end_offset":28},{"id":7474,"label":"Action","start_offset":40,"end_offset":44},{"id":7475,"label":"Entity","start_offset":49,"end_offset":55},{"id":7476,"label":"Action","start_offset":59,"end_offset":66},{"id":7477,"label":"Entity","start_offset":67,"end_offset":79},{"id":7478,"label":"Action","start_offset":83,"end_offset":87},{"id":7480,"label":"Entity","start_offset":92,"end_offset":104},{"id":7481,"label":"Action","start_offset":105,"end_offset":113}],"relations":[{"id":4320,"from_id":7473,"to_id":7474,"type":"triggers"},{"id":4321,"from_id":7474,"to_id":7475,"type":"targets"},{"id":4322,"from_id":7476,"to_id":7477,"type":"targets"},{"id":4324,"from_id":7478,"to_id":7480,"type":"targets"},{"id":4325,"from_id":7481,"to_id":7480,"type":"targets"}]}
{"id":864,"text":"#G17# As a dataset developer, I want to have an archetype that helps me package my dataset type properly.","entities":[{"id":6983,"label":"PID","start_offset":0,"end_offset":5},{"id":6984,"label":"Persona","start_offset":11,"end_offset":28},{"id":6985,"label":"Action","start_offset":40,"end_offset":44},{"id":6986,"label":"Entity","start_offset":48,"end_offset":57},{"id":6988,"label":"Action","start_offset":72,"end_offset":79},{"id":6989,"label":"Entity","start_offset":83,"end_offset":95},{"id":6990,"label":"Action","start_offset":63,"end_offset":68},{"id":6991,"label":"Entity","start_offset":69,"end_offset":71}],"relations":[{"id":4017,"from_id":6984,"to_id":6985,"type":"triggers"},{"id":4018,"from_id":6985,"to_id":6986,"type":"targets"},{"id":4019,"from_id":6988,"to_id":6989,"type":"targets"},{"id":4020,"from_id":6990,"to_id":6991,"type":"targets"}]}
{"id":865,"text":"#G17# As a dataset developer, I want to separate the interface from the implementation of a dataset type.","entities":[{"id":7095,"label":"PID","start_offset":0,"end_offset":5},{"id":7096,"label":"Persona","start_offset":11,"end_offset":28},{"id":7097,"label":"Action","start_offset":40,"end_offset":48},{"id":7098,"label":"Entity","start_offset":53,"end_offset":62},{"id":7099,"label":"Entity","start_offset":72,"end_offset":86},{"id":7100,"label":"Entity","start_offset":92,"end_offset":104}],"relations":[{"id":4083,"from_id":7096,"to_id":7097,"type":"triggers"},{"id":4084,"from_id":7097,"to_id":7098,"type":"targets"},{"id":4085,"from_id":7097,"to_id":7099,"type":"targets"},{"id":4086,"from_id":7100,"to_id":7099,"type":"contains"}]}
{"id":866,"text":"#G17# As an app developer, I want to only depend on the interface of a dataset type in my app and have the system inject the implementation at runtime.","entities":[{"id":7216,"label":"PID","start_offset":0,"end_offset":5},{"id":7217,"label":"Persona","start_offset":12,"end_offset":25},{"id":7218,"label":"Action","start_offset":37,"end_offset":48},{"id":7219,"label":"Entity","start_offset":56,"end_offset":65},{"id":7220,"label":"Entity","start_offset":71,"end_offset":83},{"id":7221,"label":"Entity","start_offset":90,"end_offset":93},{"id":7222,"label":"Action","start_offset":98,"end_offset":102},{"id":7223,"label":"Entity","start_offset":107,"end_offset":113},{"id":7224,"label":"Action","start_offset":114,"end_offset":120},{"id":7225,"label":"Entity","start_offset":125,"end_offset":139}],"relations":[{"id":4160,"from_id":7217,"to_id":7218,"type":"triggers"},{"id":4161,"from_id":7217,"to_id":7222,"type":"triggers"},{"id":4162,"from_id":7218,"to_id":7219,"type":"targets"},{"id":4163,"from_id":7220,"to_id":7219,"type":"contains"},{"id":4164,"from_id":7221,"to_id":7219,"type":"contains"},{"id":4165,"from_id":7222,"to_id":7223,"type":"targets"},{"id":4166,"from_id":7224,"to_id":7225,"type":"targets"}]}
{"id":867,"text":"#G17# As an app developer, I want to write unit tests for an app that depends on the interface of a dataset type.","entities":[{"id":7312,"label":"PID","start_offset":0,"end_offset":5},{"id":7313,"label":"Persona","start_offset":12,"end_offset":25},{"id":7314,"label":"Action","start_offset":37,"end_offset":42},{"id":7315,"label":"Entity","start_offset":43,"end_offset":53},{"id":7316,"label":"Entity","start_offset":61,"end_offset":64},{"id":7317,"label":"Action","start_offset":70,"end_offset":77},{"id":7318,"label":"Entity","start_offset":85,"end_offset":94},{"id":7319,"label":"Entity","start_offset":100,"end_offset":112}],"relations":[{"id":4242,"from_id":7313,"to_id":7314,"type":"triggers"},{"id":4243,"from_id":7314,"to_id":7315,"type":"targets"},{"id":4244,"from_id":7316,"to_id":7315,"type":"contains"},{"id":4245,"from_id":7317,"to_id":7318,"type":"targets"},{"id":4246,"from_id":7319,"to_id":7318,"type":"contains"}]}
{"id":868,"text":"#G17# As a dataset developer, I want to assign explicit versions to the code of a dataset type.","entities":[{"id":7403,"label":"PID","start_offset":0,"end_offset":5},{"id":7404,"label":"Persona","start_offset":11,"end_offset":28},{"id":7405,"label":"Action","start_offset":40,"end_offset":46},{"id":7406,"label":"Entity","start_offset":47,"end_offset":64},{"id":7407,"label":"Entity","start_offset":72,"end_offset":76},{"id":7408,"label":"Entity","start_offset":82,"end_offset":94}],"relations":[{"id":4287,"from_id":7404,"to_id":7405,"type":"triggers"},{"id":4288,"from_id":7405,"to_id":7406,"type":"targets"},{"id":4289,"from_id":7408,"to_id":7407,"type":"contains"}]}
{"id":869,"text":"#G17# As a dataset developer, I want to deploy a new version of a dataset type without affecting the dataset instances of that type.","entities":[{"id":7482,"label":"PID","start_offset":0,"end_offset":5},{"id":7483,"label":"Persona","start_offset":11,"end_offset":28},{"id":7484,"label":"Action","start_offset":40,"end_offset":46},{"id":7485,"label":"Entity","start_offset":49,"end_offset":60},{"id":7486,"label":"Entity","start_offset":66,"end_offset":78},{"id":7487,"label":"Entity","start_offset":101,"end_offset":131}],"relations":[{"id":4326,"from_id":7483,"to_id":7484,"type":"triggers"},{"id":4327,"from_id":7484,"to_id":7485,"type":"targets"},{"id":4328,"from_id":7486,"to_id":7485,"type":"contains"}]}
{"id":870,"text":"#G17# As an app developer, I want to create a dataset instance with a specific version of a dataset type.","entities":[{"id":6992,"label":"PID","start_offset":0,"end_offset":5},{"id":6993,"label":"Persona","start_offset":12,"end_offset":25},{"id":6994,"label":"Action","start_offset":37,"end_offset":43},{"id":6995,"label":"Entity","start_offset":46,"end_offset":62},{"id":6996,"label":"Entity","start_offset":70,"end_offset":86},{"id":6997,"label":"Entity","start_offset":92,"end_offset":104}],"relations":[{"id":4021,"from_id":6993,"to_id":6994,"type":"triggers"},{"id":4022,"from_id":6994,"to_id":6995,"type":"targets"},{"id":4175,"from_id":6997,"to_id":6996,"type":"contains"}]}
{"id":871,"text":"#G17# As a dataset developer, I want to explore a dataset instance created from a dataset type that was deployed by itself.","entities":[{"id":7101,"label":"PID","start_offset":0,"end_offset":5},{"id":7102,"label":"Persona","start_offset":11,"end_offset":28},{"id":7103,"label":"Action","start_offset":40,"end_offset":47},{"id":7104,"label":"Entity","start_offset":50,"end_offset":66},{"id":7105,"label":"Entity","start_offset":82,"end_offset":94}],"relations":[{"id":4087,"from_id":7102,"to_id":7103,"type":"triggers"},{"id":4088,"from_id":7103,"to_id":7104,"type":"targets"}]}
{"id":872,"text":"#G17# As a dataset developer, I want to delete outdated versions of a dataset type and I expect this to fail if there are any dataset instances with that version of the type.","entities":[{"id":7226,"label":"PID","start_offset":0,"end_offset":5},{"id":7227,"label":"Persona","start_offset":11,"end_offset":28},{"id":7228,"label":"Action","start_offset":40,"end_offset":46},{"id":7229,"label":"Entity","start_offset":47,"end_offset":64},{"id":7230,"label":"Entity","start_offset":70,"end_offset":82},{"id":7232,"label":"Action","start_offset":104,"end_offset":108},{"id":7233,"label":"Entity","start_offset":122,"end_offset":143},{"id":7234,"label":"Entity","start_offset":154,"end_offset":173}],"relations":[{"id":4167,"from_id":7227,"to_id":7228,"type":"triggers"},{"id":4168,"from_id":7228,"to_id":7229,"type":"targets"},{"id":4169,"from_id":7230,"to_id":7229,"type":"contains"},{"id":4170,"from_id":7233,"to_id":7234,"type":"contains"}]}
{"id":873,"text":"#G17# As a dataset developer, I want to list all dataset instances that use a dataset type or a specific version of a type.","entities":[{"id":7323,"label":"PID","start_offset":0,"end_offset":5},{"id":7324,"label":"Persona","start_offset":11,"end_offset":28},{"id":7325,"label":"Action","start_offset":40,"end_offset":44},{"id":7326,"label":"Entity","start_offset":45,"end_offset":66},{"id":7327,"label":"Entity","start_offset":78,"end_offset":90},{"id":7328,"label":"Entity","start_offset":96,"end_offset":112},{"id":7329,"label":"Entity","start_offset":118,"end_offset":122}],"relations":[{"id":4250,"from_id":7324,"to_id":7325,"type":"triggers"},{"id":4251,"from_id":7325,"to_id":7326,"type":"targets"},{"id":4252,"from_id":7329,"to_id":7328,"type":"targets"}]}
{"id":874,"text":"#G17# As a data scientist, I want to be able to create a dataset instance of an existing dataset type without writing code.","entities":[{"id":7413,"label":"PID","start_offset":0,"end_offset":5},{"id":7414,"label":"Persona","start_offset":11,"end_offset":25},{"id":7415,"label":"Action","start_offset":48,"end_offset":54},{"id":7416,"label":"Entity","start_offset":57,"end_offset":73},{"id":7417,"label":"Entity","start_offset":80,"end_offset":101},{"id":7418,"label":"Entity","start_offset":118,"end_offset":122}],"relations":[{"id":4292,"from_id":7414,"to_id":7415,"type":"triggers"},{"id":4293,"from_id":7415,"to_id":7416,"type":"targets"},{"id":4294,"from_id":7417,"to_id":7416,"type":"contains"}]}
{"id":875,"text":"#G17# As a data scientist, I want to be able to upgrade a dataset instance to a new version of its code.","entities":[{"id":7488,"label":"PID","start_offset":0,"end_offset":5},{"id":7489,"label":"Persona","start_offset":11,"end_offset":25},{"id":7490,"label":"Action","start_offset":48,"end_offset":55},{"id":7491,"label":"Entity","start_offset":58,"end_offset":74},{"id":7492,"label":"Entity","start_offset":80,"end_offset":91},{"id":7493,"label":"Entity","start_offset":99,"end_offset":103}],"relations":[{"id":4329,"from_id":7489,"to_id":7490,"type":"triggers"},{"id":4330,"from_id":7490,"to_id":7491,"type":"targets"},{"id":4331,"from_id":7493,"to_id":7492,"type":"contains"}]}
{"id":876,"text":"#G17# As a hydrator user, I want to create a pipeline that reads or writes an existing dataset instance.","entities":[{"id":6998,"label":"PID","start_offset":0,"end_offset":5},{"id":6999,"label":"Persona","start_offset":11,"end_offset":24},{"id":7000,"label":"Action","start_offset":36,"end_offset":42},{"id":7001,"label":"Entity","start_offset":45,"end_offset":53},{"id":7002,"label":"Action","start_offset":59,"end_offset":64},{"id":7003,"label":"Action","start_offset":68,"end_offset":74},{"id":7004,"label":"Entity","start_offset":78,"end_offset":103}],"relations":[{"id":4025,"from_id":6999,"to_id":7000,"type":"triggers"},{"id":4026,"from_id":7000,"to_id":7001,"type":"targets"},{"id":4027,"from_id":7002,"to_id":7004,"type":"targets"},{"id":4028,"from_id":7003,"to_id":7004,"type":"targets"}]}
{"id":877,"text":"#G17# As a hydrator user, I want to create a pipeline that reads or writes a new dataset instance and I want to create that dataset instance as part of pipeline creation.","entities":[{"id":7107,"label":"PID","start_offset":0,"end_offset":5},{"id":7108,"label":"Persona","start_offset":11,"end_offset":24},{"id":7109,"label":"Action","start_offset":36,"end_offset":42},{"id":7110,"label":"Entity","start_offset":45,"end_offset":53},{"id":7111,"label":"Action","start_offset":59,"end_offset":64},{"id":7112,"label":"Action","start_offset":68,"end_offset":74},{"id":7113,"label":"Entity","start_offset":77,"end_offset":97},{"id":7114,"label":"Action","start_offset":112,"end_offset":118},{"id":7115,"label":"Entity","start_offset":124,"end_offset":140},{"id":7116,"label":"Entity","start_offset":152,"end_offset":169}],"relations":[{"id":4089,"from_id":7108,"to_id":7109,"type":"triggers"},{"id":4090,"from_id":7109,"to_id":7110,"type":"targets"},{"id":4091,"from_id":7111,"to_id":7113,"type":"targets"},{"id":4092,"from_id":7112,"to_id":7113,"type":"targets"},{"id":4093,"from_id":7114,"to_id":7115,"type":"targets"},{"id":4094,"from_id":7108,"to_id":7114,"type":"triggers"},{"id":4095,"from_id":7116,"to_id":7115,"type":"contains"}]}
{"id":878,"text":"#G17# As a hydrator user, I want to specify an explicit version of the dataset types of the dataset instances created by my pipeline and I expect pipeline creation to fail if that results in incompatible upgrade of an existing dataset instance that is shared with other apps or pipelines.","entities":[{"id":7235,"label":"PID","start_offset":0,"end_offset":5},{"id":7236,"label":"Persona","start_offset":11,"end_offset":24},{"id":7237,"label":"Action","start_offset":36,"end_offset":43},{"id":7238,"label":"Entity","start_offset":47,"end_offset":63},{"id":7239,"label":"Entity","start_offset":71,"end_offset":84},{"id":7240,"label":"Entity","start_offset":92,"end_offset":109},{"id":7241,"label":"Entity","start_offset":124,"end_offset":132},{"id":7242,"label":"Entity","start_offset":146,"end_offset":163},{"id":7243,"label":"Action","start_offset":167,"end_offset":171},{"id":7244,"label":"Entity","start_offset":191,"end_offset":211},{"id":7245,"label":"Entity","start_offset":218,"end_offset":243},{"id":7246,"label":"Entity","start_offset":264,"end_offset":274},{"id":7247,"label":"Entity","start_offset":278,"end_offset":287}],"relations":[{"id":4171,"from_id":7236,"to_id":7237,"type":"triggers"},{"id":4172,"from_id":7237,"to_id":7238,"type":"targets"},{"id":4173,"from_id":7239,"to_id":7238,"type":"contains"},{"id":4174,"from_id":7240,"to_id":7239,"type":"contains"},{"id":4176,"from_id":7245,"to_id":7244,"type":"contains"},{"id":4177,"from_id":7246,"to_id":7245,"type":"contains"},{"id":4178,"from_id":7247,"to_id":7245,"type":"contains"}]}
{"id":879,"text":"#G17# As a hydrator user, I want to explore the datasets created by my pipeline.","entities":[{"id":7330,"label":"PID","start_offset":0,"end_offset":5},{"id":7331,"label":"Persona","start_offset":11,"end_offset":24},{"id":7332,"label":"Action","start_offset":36,"end_offset":43},{"id":7333,"label":"Entity","start_offset":48,"end_offset":56},{"id":7334,"label":"Entity","start_offset":71,"end_offset":79}],"relations":[{"id":4253,"from_id":7331,"to_id":7332,"type":"triggers"},{"id":4254,"from_id":7332,"to_id":7333,"type":"targets"}]}
{"id":880,"text":"#G17# As a hydrator user, I want to ensure that all dataset instances created by apps are available as sinks and sources for pipelines.","entities":[{"id":7419,"label":"PID","start_offset":0,"end_offset":5},{"id":7420,"label":"Persona","start_offset":11,"end_offset":24},{"id":7421,"label":"Action","start_offset":36,"end_offset":42},{"id":7422,"label":"Entity","start_offset":48,"end_offset":69},{"id":7423,"label":"Entity","start_offset":103,"end_offset":108},{"id":7424,"label":"Entity","start_offset":113,"end_offset":120},{"id":7425,"label":"Entity","start_offset":125,"end_offset":134}],"relations":[{"id":4295,"from_id":7420,"to_id":7421,"type":"triggers"},{"id":4301,"from_id":7422,"to_id":7423,"type":"contains"},{"id":4302,"from_id":7422,"to_id":7424,"type":"contains"}]}
{"id":881,"text":"#G17# As an app developer, I want to ensure that all dataset instances created by Hydrator pipelines are accessible to the app.","entities":[{"id":7494,"label":"PID","start_offset":0,"end_offset":5},{"id":7495,"label":"Persona","start_offset":12,"end_offset":25},{"id":7496,"label":"Action","start_offset":37,"end_offset":43},{"id":7497,"label":"Entity","start_offset":49,"end_offset":70},{"id":7498,"label":"Entity","start_offset":82,"end_offset":100},{"id":7499,"label":"Entity","start_offset":123,"end_offset":126}],"relations":[{"id":4332,"from_id":7495,"to_id":7496,"type":"triggers"}]}
{"id":882,"text":"#G17# As a plugin developer, I want to include the code for a dataset type in the plugin artifact, so that when a pipeline using this plugin is created a dataset instance of that type is created and it is explorable and available to apps.","entities":[{"id":7005,"label":"PID","start_offset":0,"end_offset":5},{"id":7006,"label":"Persona","start_offset":11,"end_offset":27},{"id":7007,"label":"Action","start_offset":39,"end_offset":46},{"id":7008,"label":"Entity","start_offset":51,"end_offset":55},{"id":7009,"label":"Entity","start_offset":62,"end_offset":74},{"id":7010,"label":"Entity","start_offset":82,"end_offset":97},{"id":7011,"label":"Benefit","start_offset":107,"end_offset":238},{"id":7012,"label":"Entity","start_offset":114,"end_offset":122},{"id":7013,"label":"Action","start_offset":123,"end_offset":128},{"id":7014,"label":"Entity","start_offset":134,"end_offset":140},{"id":7015,"label":"Action","start_offset":144,"end_offset":151},{"id":7018,"label":"Action","start_offset":187,"end_offset":194},{"id":7019,"label":"Entity","start_offset":233,"end_offset":237},{"id":7207,"label":"Entity","start_offset":154,"end_offset":183}],"relations":[{"id":4029,"from_id":7006,"to_id":7007,"type":"triggers"},{"id":4030,"from_id":7007,"to_id":7008,"type":"targets"},{"id":4032,"from_id":7010,"to_id":7008,"type":"contains"},{"id":4033,"from_id":7013,"to_id":7014,"type":"targets"},{"id":4036,"from_id":7015,"to_id":7012,"type":"targets"},{"id":4151,"from_id":7018,"to_id":7207,"type":"targets"}]}
{"id":883,"text":"#G17# As a plugin developer, I want to use a custom dataset type that was deployed independently or as part of an app inside the plugin.","entities":[{"id":7118,"label":"Persona","start_offset":11,"end_offset":27},{"id":7119,"label":"PID","start_offset":0,"end_offset":5},{"id":7120,"label":"Action","start_offset":39,"end_offset":42},{"id":7121,"label":"Entity","start_offset":45,"end_offset":64},{"id":7122,"label":"Entity","start_offset":114,"end_offset":117},{"id":7123,"label":"Entity","start_offset":129,"end_offset":135}],"relations":[{"id":4096,"from_id":7118,"to_id":7120,"type":"triggers"},{"id":4097,"from_id":7120,"to_id":7121,"type":"targets"},{"id":4098,"from_id":7122,"to_id":7121,"type":"contains"},{"id":4099,"from_id":7123,"to_id":7121,"type":"contains"}]}
{"id":884,"text":"#G17# As a plugin developer, I want to upgrade the code of a dataset type used by a dataset instance created by that plugin when I deploy a new version of the plugin and update the pipeline to use that version.","entities":[{"id":7248,"label":"PID","start_offset":0,"end_offset":5},{"id":7249,"label":"Persona","start_offset":11,"end_offset":27},{"id":7250,"label":"Action","start_offset":39,"end_offset":46},{"id":7251,"label":"Entity","start_offset":51,"end_offset":55},{"id":7252,"label":"Entity","start_offset":61,"end_offset":73},{"id":7253,"label":"Entity","start_offset":84,"end_offset":100},{"id":7254,"label":"Entity","start_offset":117,"end_offset":123},{"id":7255,"label":"Action","start_offset":131,"end_offset":137},{"id":7256,"label":"Entity","start_offset":140,"end_offset":151},{"id":7257,"label":"Entity","start_offset":159,"end_offset":165},{"id":7258,"label":"Action","start_offset":170,"end_offset":176},{"id":7259,"label":"Entity","start_offset":181,"end_offset":189},{"id":7260,"label":"Action","start_offset":193,"end_offset":196},{"id":7261,"label":"Entity","start_offset":202,"end_offset":209}],"relations":[{"id":4179,"from_id":7249,"to_id":7250,"type":"triggers"},{"id":4180,"from_id":7250,"to_id":7251,"type":"targets"},{"id":4181,"from_id":7252,"to_id":7251,"type":"contains"},{"id":4182,"from_id":7255,"to_id":7256,"type":"targets"},{"id":4183,"from_id":7257,"to_id":7256,"type":"contains"},{"id":4184,"from_id":7258,"to_id":7259,"type":"targets"},{"id":4185,"from_id":7260,"to_id":7261,"type":"targets"}]}
{"id":885,"text":"#G17# As a pipeline developer, I want to upgrade a dataset instance to a newer version of the code after the pipeline was created.","entities":[{"id":7335,"label":"PID","start_offset":0,"end_offset":5},{"id":7336,"label":"Persona","start_offset":11,"end_offset":29},{"id":7337,"label":"Action","start_offset":41,"end_offset":48},{"id":7338,"label":"Entity","start_offset":51,"end_offset":67},{"id":7339,"label":"Entity","start_offset":73,"end_offset":86},{"id":7340,"label":"Entity","start_offset":94,"end_offset":98},{"id":7341,"label":"Entity","start_offset":109,"end_offset":117},{"id":7342,"label":"Action","start_offset":122,"end_offset":129}],"relations":[{"id":4255,"from_id":7336,"to_id":7337,"type":"triggers"},{"id":4256,"from_id":7337,"to_id":7338,"type":"targets"},{"id":4257,"from_id":7340,"to_id":7339,"type":"contains"},{"id":4258,"from_id":7342,"to_id":7341,"type":"targets"}]}
{"id":886,"text":"#G17# As a dataset developer, I want to have the option of implementing an upgrade step for when a dataset instance is upgraded to a new version of the dataset type.","entities":[{"id":7426,"label":"PID","start_offset":0,"end_offset":5},{"id":7427,"label":"Persona","start_offset":11,"end_offset":28},{"id":7428,"label":"Action","start_offset":40,"end_offset":44},{"id":7429,"label":"Entity","start_offset":49,"end_offset":55},{"id":7430,"label":"Action","start_offset":59,"end_offset":71},{"id":7431,"label":"Entity","start_offset":75,"end_offset":87},{"id":7432,"label":"Entity","start_offset":99,"end_offset":115},{"id":7433,"label":"Entity","start_offset":133,"end_offset":144},{"id":7434,"label":"Entity","start_offset":152,"end_offset":164},{"id":7435,"label":"Action","start_offset":119,"end_offset":127}],"relations":[{"id":4297,"from_id":7427,"to_id":7428,"type":"triggers"},{"id":4298,"from_id":7428,"to_id":7429,"type":"targets"},{"id":4299,"from_id":7430,"to_id":7431,"type":"targets"},{"id":4300,"from_id":7434,"to_id":7433,"type":"contains"},{"id":4303,"from_id":7435,"to_id":7432,"type":"targets"}]}
{"id":887,"text":"#G17# As a dataset developer, I want to have a way to reject an upgrade of a dataset instance to a newer version of it type if the upgrade is not compatible.","entities":[{"id":7500,"label":"PID","start_offset":0,"end_offset":5},{"id":7501,"label":"Persona","start_offset":11,"end_offset":28},{"id":7502,"label":"Action","start_offset":40,"end_offset":44},{"id":7503,"label":"Entity","start_offset":47,"end_offset":50},{"id":7504,"label":"Action","start_offset":54,"end_offset":60},{"id":7505,"label":"Entity","start_offset":64,"end_offset":71},{"id":7506,"label":"Entity","start_offset":77,"end_offset":93},{"id":7507,"label":"Entity","start_offset":99,"end_offset":112},{"id":7508,"label":"Entity","start_offset":119,"end_offset":123},{"id":7509,"label":"Entity","start_offset":131,"end_offset":138}],"relations":[{"id":4334,"from_id":7501,"to_id":7502,"type":"triggers"},{"id":4335,"from_id":7502,"to_id":7503,"type":"targets"},{"id":4336,"from_id":7504,"to_id":7505,"type":"targets"},{"id":4337,"from_id":7506,"to_id":7505,"type":"contains"},{"id":4338,"from_id":7508,"to_id":7507,"type":"contains"}]}
{"id":888,"text":"#G17# As a dataset developer, I want to have the option of implementing a migration procedure that can be run after an upgrade of a dataset instance to a new version of it type.","entities":[{"id":7020,"label":"PID","start_offset":0,"end_offset":5},{"id":7021,"label":"Persona","start_offset":11,"end_offset":28},{"id":7022,"label":"Action","start_offset":40,"end_offset":44},{"id":7023,"label":"Entity","start_offset":49,"end_offset":55},{"id":7024,"label":"Action","start_offset":59,"end_offset":71},{"id":7025,"label":"Entity","start_offset":74,"end_offset":93},{"id":7026,"label":"Action","start_offset":106,"end_offset":109},{"id":7028,"label":"Entity","start_offset":132,"end_offset":148},{"id":7210,"label":"Entity","start_offset":119,"end_offset":126},{"id":7211,"label":"Entity","start_offset":154,"end_offset":176}],"relations":[{"id":4037,"from_id":7021,"to_id":7022,"type":"triggers"},{"id":4038,"from_id":7022,"to_id":7023,"type":"targets"},{"id":4039,"from_id":7024,"to_id":7025,"type":"targets"},{"id":4040,"from_id":7026,"to_id":7025,"type":"targets"},{"id":4156,"from_id":7028,"to_id":7210,"type":"contains"}]}
{"id":889,"text":"#G17# As a developer, I want to take a dataset offline, so that I can perform a long-running maintenance or migration procedure.","entities":[{"id":7125,"label":"Persona","start_offset":11,"end_offset":20},{"id":7126,"label":"PID","start_offset":0,"end_offset":5},{"id":7127,"label":"Action","start_offset":32,"end_offset":36},{"id":7128,"label":"Entity","start_offset":39,"end_offset":46},{"id":7129,"label":"Benefit","start_offset":64,"end_offset":128},{"id":7130,"label":"Action","start_offset":70,"end_offset":77},{"id":7131,"label":"Entity","start_offset":80,"end_offset":104},{"id":7132,"label":"Entity","start_offset":108,"end_offset":127}],"relations":[{"id":4100,"from_id":7125,"to_id":7127,"type":"triggers"},{"id":4101,"from_id":7127,"to_id":7128,"type":"targets"},{"id":4102,"from_id":7130,"to_id":7131,"type":"targets"},{"id":4103,"from_id":7130,"to_id":7132,"type":"targets"}]}
{"id":890,"text":"#G17# As a dataset developer, I want to implement custom administrative operations such as \"compaction\" or \"rebalance\" that are no common to all dataset types.","entities":[{"id":7262,"label":"PID","start_offset":0,"end_offset":5},{"id":7263,"label":"Persona","start_offset":11,"end_offset":28},{"id":7264,"label":"Action","start_offset":40,"end_offset":49},{"id":7265,"label":"Entity","start_offset":50,"end_offset":82},{"id":7266,"label":"Entity","start_offset":91,"end_offset":103},{"id":7267,"label":"Entity","start_offset":107,"end_offset":118},{"id":7268,"label":"Entity","start_offset":141,"end_offset":158}],"relations":[{"id":4186,"from_id":7263,"to_id":7264,"type":"triggers"},{"id":4187,"from_id":7264,"to_id":7265,"type":"targets"},{"id":4188,"from_id":7265,"to_id":7266,"type":"contains"},{"id":4189,"from_id":7265,"to_id":7267,"type":"contains"}]}
{"id":891,"text":"#G17# As an app developer, I want to perform custom administrative operations on dataset instances from my app and the CLI and REST or the UI.","entities":[{"id":7343,"label":"PID","start_offset":0,"end_offset":5},{"id":7344,"label":"Persona","start_offset":12,"end_offset":25},{"id":7345,"label":"Action","start_offset":37,"end_offset":44},{"id":7346,"label":"Entity","start_offset":45,"end_offset":77},{"id":7347,"label":"Entity","start_offset":81,"end_offset":98},{"id":7348,"label":"Entity","start_offset":107,"end_offset":110},{"id":7349,"label":"Entity","start_offset":119,"end_offset":123},{"id":7350,"label":"Entity","start_offset":127,"end_offset":131},{"id":7351,"label":"Entity","start_offset":139,"end_offset":141}],"relations":[{"id":4259,"from_id":7344,"to_id":7345,"type":"triggers"},{"id":4260,"from_id":7345,"to_id":7346,"type":"targets"},{"id":4261,"from_id":7348,"to_id":7346,"type":"contains"},{"id":4262,"from_id":7349,"to_id":7346,"type":"contains"},{"id":4263,"from_id":7350,"to_id":7346,"type":"contains"},{"id":4264,"from_id":7351,"to_id":7346,"type":"contains"}]}
{"id":892,"text":"#G17# As a user, I want to find out what properties are supported by the dataset type what values are allowed and what the defaults are when creating a dataset instance.","entities":[{"id":7436,"label":"PID","start_offset":0,"end_offset":5},{"id":7437,"label":"Persona","start_offset":11,"end_offset":15},{"id":7438,"label":"Action","start_offset":27,"end_offset":35},{"id":7439,"label":"Entity","start_offset":41,"end_offset":51},{"id":7440,"label":"Entity","start_offset":73,"end_offset":85},{"id":7441,"label":"Entity","start_offset":91,"end_offset":97},{"id":7442,"label":"Entity","start_offset":123,"end_offset":131},{"id":7443,"label":"Action","start_offset":141,"end_offset":149},{"id":7444,"label":"Entity","start_offset":152,"end_offset":168}],"relations":[{"id":4304,"from_id":7437,"to_id":7438,"type":"triggers"},{"id":4305,"from_id":7438,"to_id":7439,"type":"targets"},{"id":4306,"from_id":7438,"to_id":7441,"type":"targets"},{"id":4307,"from_id":7438,"to_id":7442,"type":"targets"},{"id":4308,"from_id":7443,"to_id":7444,"type":"targets"}]}
{"id":893,"text":"#G17# As a user, I want to specify the schema of a dataset in a uniform way across all dataset types.","entities":[{"id":7510,"label":"PID","start_offset":0,"end_offset":5},{"id":7511,"label":"Persona","start_offset":11,"end_offset":15},{"id":7512,"label":"Action","start_offset":27,"end_offset":34},{"id":7513,"label":"Entity","start_offset":39,"end_offset":45},{"id":7514,"label":"Entity","start_offset":51,"end_offset":58},{"id":7515,"label":"Entity","start_offset":64,"end_offset":75},{"id":7516,"label":"Entity","start_offset":83,"end_offset":100}],"relations":[{"id":4339,"from_id":7511,"to_id":7512,"type":"triggers"},{"id":4340,"from_id":7512,"to_id":7513,"type":"targets"},{"id":4341,"from_id":7514,"to_id":7513,"type":"contains"}]}
{"id":894,"text":"#G17# As a user, I want to specify schema as a JSON string.","entities":[{"id":7031,"label":"PID","start_offset":0,"end_offset":5},{"id":7032,"label":"Persona","start_offset":11,"end_offset":15},{"id":7033,"label":"Action","start_offset":27,"end_offset":34},{"id":7034,"label":"Entity","start_offset":35,"end_offset":41},{"id":7035,"label":"Entity","start_offset":47,"end_offset":58}],"relations":[{"id":4044,"from_id":7032,"to_id":7033,"type":"triggers"},{"id":4045,"from_id":7033,"to_id":7034,"type":"targets"}]}
{"id":895,"text":"#G17# As a user, I want to specify schema as a SQL schema string.","entities":[{"id":7133,"label":"PID","start_offset":0,"end_offset":5},{"id":7134,"label":"Persona","start_offset":11,"end_offset":15},{"id":7135,"label":"Action","start_offset":27,"end_offset":34},{"id":7136,"label":"Entity","start_offset":35,"end_offset":41},{"id":7137,"label":"Entity","start_offset":47,"end_offset":64}],"relations":[{"id":4104,"from_id":7134,"to_id":7135,"type":"triggers"},{"id":4105,"from_id":7135,"to_id":7136,"type":"targets"}]}
{"id":896,"text":"#G17# As a user, I want to configure time-to-live in a uniform way across all dataset types.","entities":[{"id":7269,"label":"PID","start_offset":0,"end_offset":5},{"id":7270,"label":"Persona","start_offset":11,"end_offset":15},{"id":7271,"label":"Action","start_offset":27,"end_offset":36},{"id":7272,"label":"Entity","start_offset":37,"end_offset":49},{"id":7273,"label":"Entity","start_offset":74,"end_offset":91}],"relations":[{"id":4197,"from_id":7270,"to_id":7271,"type":"triggers"},{"id":4198,"from_id":7271,"to_id":7272,"type":"targets"},{"id":4199,"from_id":7273,"to_id":7272,"type":"contains"}]}
{"id":897,"text":"#G17# As a user, I want to see the properties that were used to configure a dataset instance.","entities":[{"id":7352,"label":"PID","start_offset":0,"end_offset":5},{"id":7353,"label":"Persona","start_offset":11,"end_offset":15},{"id":7354,"label":"Action","start_offset":27,"end_offset":30},{"id":7355,"label":"Entity","start_offset":35,"end_offset":45},{"id":7356,"label":"Entity","start_offset":76,"end_offset":92},{"id":7357,"label":"Action","start_offset":64,"end_offset":73}],"relations":[{"id":4265,"from_id":7353,"to_id":7354,"type":"triggers"},{"id":4266,"from_id":7354,"to_id":7355,"type":"targets"},{"id":4267,"from_id":7357,"to_id":7356,"type":"targets"}]}
{"id":898,"text":"#G17# As a user, I want to find out what properties of a dataset can be updated.","entities":[{"id":7445,"label":"PID","start_offset":0,"end_offset":5},{"id":7446,"label":"Persona","start_offset":11,"end_offset":15},{"id":7447,"label":"Action","start_offset":27,"end_offset":35},{"id":7448,"label":"Entity","start_offset":41,"end_offset":51},{"id":7449,"label":"Entity","start_offset":57,"end_offset":64},{"id":7642,"label":"Action","start_offset":72,"end_offset":79}],"relations":[{"id":4309,"from_id":7446,"to_id":7447,"type":"triggers"},{"id":4310,"from_id":7447,"to_id":7448,"type":"targets"},{"id":4311,"from_id":7449,"to_id":7448,"type":"contains"},{"id":4411,"from_id":7642,"to_id":7448,"type":"targets"}]}
{"id":899,"text":"#G17# As a user, I want to update the properties of a dataset instance and I expect this to fail if the new properties are not compatible with a meaningful error message.","entities":[{"id":7517,"label":"PID","start_offset":0,"end_offset":5},{"id":7518,"label":"Persona","start_offset":11,"end_offset":15},{"id":7519,"label":"Action","start_offset":27,"end_offset":33},{"id":7520,"label":"Entity","start_offset":38,"end_offset":48},{"id":7521,"label":"Entity","start_offset":54,"end_offset":70},{"id":7522,"label":"Action","start_offset":92,"end_offset":96},{"id":7523,"label":"Entity","start_offset":104,"end_offset":118},{"id":7524,"label":"Entity","start_offset":145,"end_offset":169}],"relations":[{"id":4342,"from_id":7518,"to_id":7519,"type":"triggers"},{"id":4343,"from_id":7519,"to_id":7520,"type":"targets"},{"id":4344,"from_id":7521,"to_id":7520,"type":"contains"}]}
{"id":900,"text":"#G17# As a user, I want to update a single property of a dataset instance without knowing all other properties.","entities":[{"id":7036,"label":"PID","start_offset":0,"end_offset":5},{"id":7037,"label":"Persona","start_offset":11,"end_offset":15},{"id":7038,"label":"Action","start_offset":27,"end_offset":33},{"id":7039,"label":"Entity","start_offset":36,"end_offset":51},{"id":7040,"label":"Entity","start_offset":57,"end_offset":73},{"id":7042,"label":"Entity","start_offset":90,"end_offset":110}],"relations":[{"id":4046,"from_id":7037,"to_id":7038,"type":"triggers"},{"id":4047,"from_id":7038,"to_id":7039,"type":"targets"},{"id":4048,"from_id":7040,"to_id":7039,"type":"contains"},{"id":4050,"from_id":7040,"to_id":7042,"type":"contains"}]}
{"id":901,"text":"#G17# As a user, I want to remove a single property of a dataset instance without knowing all other properties.","entities":[{"id":7138,"label":"PID","start_offset":0,"end_offset":5},{"id":7139,"label":"Persona","start_offset":11,"end_offset":15},{"id":7140,"label":"Action","start_offset":27,"end_offset":33},{"id":7141,"label":"Entity","start_offset":36,"end_offset":51},{"id":7142,"label":"Entity","start_offset":57,"end_offset":73},{"id":7144,"label":"Entity","start_offset":90,"end_offset":110}],"relations":[{"id":4106,"from_id":7139,"to_id":7140,"type":"triggers"},{"id":4107,"from_id":7140,"to_id":7141,"type":"targets"},{"id":4108,"from_id":7142,"to_id":7141,"type":"contains"},{"id":4110,"from_id":7142,"to_id":7144,"type":"contains"}]}
{"id":902,"text":"#G17# As a user, I want to trigger a migration process for a dataset if updating its properties requires that.","entities":[{"id":7283,"label":"PID","start_offset":0,"end_offset":5},{"id":7284,"label":"Persona","start_offset":11,"end_offset":15},{"id":7285,"label":"Action","start_offset":27,"end_offset":34},{"id":7286,"label":"Entity","start_offset":37,"end_offset":54},{"id":7287,"label":"Entity","start_offset":61,"end_offset":68},{"id":7288,"label":"Action","start_offset":72,"end_offset":80},{"id":7289,"label":"Entity","start_offset":85,"end_offset":95},{"id":7290,"label":"Action","start_offset":96,"end_offset":104}],"relations":[{"id":4226,"from_id":7284,"to_id":7285,"type":"triggers"},{"id":4227,"from_id":7285,"to_id":7286,"type":"targets"},{"id":4228,"from_id":7287,"to_id":7286,"type":"contains"},{"id":4229,"from_id":7290,"to_id":7286,"type":"targets"},{"id":4230,"from_id":7288,"to_id":7289,"type":"targets"},{"id":4231,"from_id":7287,"to_id":7289,"type":"contains"}]}
{"id":903,"text":"#G17# As a user, I want to ensure that if reconfiguration of a dataset fails then no changes have taken effect, so that all steps required to reconfigure a dataset must be done as a single atomic action.","entities":[{"id":7358,"label":"PID","start_offset":0,"end_offset":5},{"id":7359,"label":"Persona","start_offset":11,"end_offset":15},{"id":7360,"label":"Action","start_offset":27,"end_offset":33},{"id":7361,"label":"Entity","start_offset":42,"end_offset":57},{"id":7362,"label":"Entity","start_offset":63,"end_offset":70},{"id":7363,"label":"Action","start_offset":71,"end_offset":76},{"id":7364,"label":"Benefit","start_offset":120,"end_offset":203},{"id":7366,"label":"Action","start_offset":142,"end_offset":153},{"id":7367,"label":"Entity","start_offset":156,"end_offset":163},{"id":7368,"label":"Entity","start_offset":182,"end_offset":202},{"id":7373,"label":"Entity","start_offset":120,"end_offset":138}],"relations":[{"id":4268,"from_id":7359,"to_id":7360,"type":"triggers"},{"id":4269,"from_id":7362,"to_id":7361,"type":"contains"},{"id":4270,"from_id":7366,"to_id":7367,"type":"targets"}]}
{"id":904,"text":"#G17# As an app developer, I want to ensure that application creation fails if any of its datasets cannot be created.","entities":[{"id":7459,"label":"PID","start_offset":0,"end_offset":5},{"id":7460,"label":"Persona","start_offset":12,"end_offset":25},{"id":7461,"label":"Action","start_offset":37,"end_offset":43},{"id":7462,"label":"Entity","start_offset":49,"end_offset":69},{"id":7463,"label":"Action","start_offset":70,"end_offset":75},{"id":7464,"label":"Entity","start_offset":90,"end_offset":98}],"relations":[{"id":4314,"from_id":7460,"to_id":7461,"type":"triggers"},{"id":4315,"from_id":7462,"to_id":7464,"type":"contains"}]}
{"id":905,"text":"#G17# As an app developer, I want to ensure that application redeployment fails if any of its datasets cannot be reconfigured.","entities":[{"id":7525,"label":"PID","start_offset":0,"end_offset":5},{"id":7526,"label":"Persona","start_offset":12,"end_offset":25},{"id":7527,"label":"Action","start_offset":37,"end_offset":43},{"id":7528,"label":"Entity","start_offset":49,"end_offset":73},{"id":7529,"label":"Action","start_offset":74,"end_offset":79},{"id":7530,"label":"Entity","start_offset":94,"end_offset":102}],"relations":[{"id":4345,"from_id":7526,"to_id":7527,"type":"triggers"},{"id":4347,"from_id":7528,"to_id":7530,"type":"contains"}]}
{"id":906,"text":"#G17# As an app developer, I want to tolerate existing datasets if their properties are different but compatible when creating a dataset as part of app deployment.","entities":[{"id":7043,"label":"PID","start_offset":0,"end_offset":5},{"id":7044,"label":"Persona","start_offset":12,"end_offset":25},{"id":7045,"label":"Action","start_offset":37,"end_offset":45},{"id":7046,"label":"Entity","start_offset":46,"end_offset":63},{"id":7047,"label":"Entity","start_offset":73,"end_offset":83},{"id":7048,"label":"Action","start_offset":118,"end_offset":126},{"id":7049,"label":"Entity","start_offset":129,"end_offset":136},{"id":7050,"label":"Entity","start_offset":148,"end_offset":162}],"relations":[{"id":4051,"from_id":7044,"to_id":7045,"type":"triggers"},{"id":4052,"from_id":7045,"to_id":7046,"type":"targets"},{"id":4053,"from_id":7046,"to_id":7047,"type":"contains"},{"id":4054,"from_id":7048,"to_id":7049,"type":"targets"}]}
{"id":907,"text":"#G17# As a pipeline designer, I want to get a meaningful error message when pipeline creation fails when I use an existing dataset as a sink or source, so that I know that the schema or any other property of the dataset is incompatible with what the pipeline requires.","entities":[{"id":7145,"label":"PID","start_offset":0,"end_offset":5},{"id":7146,"label":"Persona","start_offset":11,"end_offset":28},{"id":7147,"label":"Action","start_offset":40,"end_offset":43},{"id":7148,"label":"Entity","start_offset":46,"end_offset":70},{"id":7149,"label":"Entity","start_offset":76,"end_offset":93},{"id":7150,"label":"Action","start_offset":94,"end_offset":99},{"id":7151,"label":"Action","start_offset":107,"end_offset":110},{"id":7152,"label":"Entity","start_offset":114,"end_offset":130},{"id":7153,"label":"Entity","start_offset":136,"end_offset":140},{"id":7154,"label":"Entity","start_offset":144,"end_offset":150},{"id":7155,"label":"Benefit","start_offset":160,"end_offset":268},{"id":7156,"label":"Action","start_offset":162,"end_offset":166},{"id":7157,"label":"Entity","start_offset":176,"end_offset":182},{"id":7158,"label":"Entity","start_offset":186,"end_offset":204},{"id":7159,"label":"Entity","start_offset":212,"end_offset":219},{"id":7160,"label":"Entity","start_offset":250,"end_offset":258},{"id":7163,"label":"Action","start_offset":259,"end_offset":267},{"id":7164,"label":"Entity","start_offset":241,"end_offset":245}],"relations":[{"id":4111,"from_id":7146,"to_id":7147,"type":"triggers"},{"id":4112,"from_id":7147,"to_id":7148,"type":"targets"},{"id":4114,"from_id":7151,"to_id":7152,"type":"targets"},{"id":4115,"from_id":7156,"to_id":7157,"type":"targets"},{"id":4116,"from_id":7156,"to_id":7158,"type":"targets"},{"id":4117,"from_id":7159,"to_id":7158,"type":"contains"},{"id":4119,"from_id":7163,"to_id":7164,"type":"targets"}]}
{"id":908,"text":"#G17# As a user, I want to specify as part of dataset configuration whether it is explorable.","entities":[{"id":7291,"label":"PID","start_offset":0,"end_offset":5},{"id":7292,"label":"Persona","start_offset":11,"end_offset":15},{"id":7293,"label":"Action","start_offset":27,"end_offset":34},{"id":7294,"label":"Entity","start_offset":46,"end_offset":67}],"relations":[{"id":4232,"from_id":7292,"to_id":7293,"type":"triggers"},{"id":4233,"from_id":7293,"to_id":7294,"type":"targets"}]}
{"id":909,"text":"#G17# As a user, I want to specify the explore schema separately.","entities":[{"id":7369,"label":"PID","start_offset":0,"end_offset":5},{"id":7370,"label":"Persona","start_offset":11,"end_offset":15},{"id":7371,"label":"Action","start_offset":27,"end_offset":34},{"id":7372,"label":"Entity","start_offset":39,"end_offset":53}],"relations":[{"id":4271,"from_id":7370,"to_id":7371,"type":"triggers"},{"id":4272,"from_id":7371,"to_id":7372,"type":"targets"}]}
{"id":910,"text":"#G17# As a user, I want to ensure that dataset creation fails if the dataset cannot be enabled for explore.","entities":[{"id":7452,"label":"PID","start_offset":0,"end_offset":5},{"id":7453,"label":"Persona","start_offset":11,"end_offset":15},{"id":7454,"label":"Action","start_offset":27,"end_offset":33},{"id":7455,"label":"Entity","start_offset":39,"end_offset":55},{"id":7456,"label":"Action","start_offset":56,"end_offset":61},{"id":7457,"label":"Entity","start_offset":69,"end_offset":76},{"id":7458,"label":"Entity","start_offset":99,"end_offset":106}],"relations":[{"id":4313,"from_id":7453,"to_id":7454,"type":"triggers"}]}
{"id":911,"text":"#G17# As a user, I want to ensure that dataset reconfiguration fails if the corresponding update of the explore table fails.","entities":[{"id":7531,"label":"PID","start_offset":0,"end_offset":5},{"id":7532,"label":"Persona","start_offset":11,"end_offset":15},{"id":7533,"label":"Action","start_offset":27,"end_offset":33},{"id":7534,"label":"Entity","start_offset":39,"end_offset":62},{"id":7535,"label":"Action","start_offset":63,"end_offset":68},{"id":7536,"label":"Entity","start_offset":76,"end_offset":96},{"id":7537,"label":"Entity","start_offset":104,"end_offset":117},{"id":7538,"label":"Action","start_offset":118,"end_offset":123}],"relations":[{"id":4348,"from_id":7532,"to_id":7533,"type":"triggers"},{"id":4349,"from_id":7537,"to_id":7536,"type":"contains"}]}
{"id":912,"text":"#G17# As a user, I want to ensure that a dataset operation fails if it fails to make its required changes to explore.","entities":[{"id":7051,"label":"PID","start_offset":0,"end_offset":5},{"id":7052,"label":"Persona","start_offset":11,"end_offset":15},{"id":7053,"label":"Action","start_offset":27,"end_offset":33},{"id":7054,"label":"Entity","start_offset":41,"end_offset":58},{"id":7055,"label":"Action","start_offset":59,"end_offset":64},{"id":7056,"label":"Action","start_offset":71,"end_offset":84},{"id":7057,"label":"Entity","start_offset":89,"end_offset":105},{"id":7177,"label":"Entity","start_offset":109,"end_offset":116}],"relations":[{"id":4055,"from_id":7052,"to_id":7053,"type":"triggers"},{"id":4058,"from_id":7056,"to_id":7057,"type":"targets"}]}
{"id":913,"text":"#G17# As a user, I want to ensure that an update of explore never leads to silent loss of data or data available for explore.","entities":[{"id":7165,"label":"PID","start_offset":0,"end_offset":5},{"id":7166,"label":"Persona","start_offset":11,"end_offset":15},{"id":7167,"label":"Action","start_offset":27,"end_offset":33},{"id":7168,"label":"Entity","start_offset":42,"end_offset":48},{"id":7169,"label":"Entity","start_offset":52,"end_offset":59},{"id":7172,"label":"Entity","start_offset":98,"end_offset":112},{"id":7173,"label":"Entity","start_offset":117,"end_offset":124},{"id":7175,"label":"Entity","start_offset":90,"end_offset":94},{"id":7176,"label":"Action","start_offset":60,"end_offset":86}],"relations":[{"id":4120,"from_id":7166,"to_id":7167,"type":"triggers"},{"id":4122,"from_id":7169,"to_id":7168,"type":"contains"},{"id":4124,"from_id":7176,"to_id":7175,"type":"targets"},{"id":4125,"from_id":7176,"to_id":7172,"type":"targets"}]}
{"id":914,"text":"#G17# As a user, I want to enable explore for a dataset that was not configured for explore initially.","entities":[{"id":7295,"label":"PID","start_offset":0,"end_offset":5},{"id":7296,"label":"Persona","start_offset":11,"end_offset":15},{"id":7297,"label":"Action","start_offset":27,"end_offset":33},{"id":7298,"label":"Entity","start_offset":34,"end_offset":41},{"id":7299,"label":"Entity","start_offset":48,"end_offset":55},{"id":7300,"label":"Entity","start_offset":84,"end_offset":91}],"relations":[{"id":4234,"from_id":7296,"to_id":7297,"type":"triggers"},{"id":4235,"from_id":7297,"to_id":7298,"type":"targets"}]}
{"id":915,"text":"#G17# As a user, I want to disable explore for a dataset that was configured for explore initially.","entities":[{"id":7374,"label":"PID","start_offset":0,"end_offset":5},{"id":7375,"label":"Persona","start_offset":11,"end_offset":15},{"id":7376,"label":"Action","start_offset":27,"end_offset":34},{"id":7377,"label":"Entity","start_offset":35,"end_offset":42},{"id":7378,"label":"Entity","start_offset":49,"end_offset":56},{"id":7379,"label":"Entity","start_offset":81,"end_offset":88}],"relations":[{"id":4273,"from_id":7375,"to_id":7376,"type":"triggers"},{"id":4274,"from_id":7376,"to_id":7377,"type":"targets"}]}
